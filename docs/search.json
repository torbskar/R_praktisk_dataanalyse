[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Veldig praktisk dataanalyse med R",
    "section": "",
    "text": "Forord\nDette notatet er ment som en praktisk innføring i bruk av R til en del vanlige problemstillinger som studenter ofte kommer borti når man jobber med data. Teksten er ment som en ganske grunnleggende innføring for praktikere. Fokuset er å vise løsninger som funker uten for mye mikk-makk.\nDet er alltid flere måter å gjøre ting på, og noen undervisere eller studenter foretrukket om man valgte en annen løsning. Noen alternativer er dekket i appendix. Hovedteksten dekker altså mine anbefalinger. Mine anbefaleinger kan være basert på flere typer hensyn slik som effektivitet, konsistens med andre løsninger og funksjonalitet.\nMen dette dokumentet er også ment som et oppslagsverk slik at man lett skal kunne finne det man leter etter."
  },
  {
    "objectID": "index.html#tolkning-og-teori",
    "href": "index.html#tolkning-og-teori",
    "title": "Veldig praktisk dataanalyse med R",
    "section": "Tolkning og teori",
    "text": "Tolkning og teori\nJeg har inkludert et innledende kapittel om statistikk og substansiell teori. Dette virker kanskje litt rart å ta inn i et slikt notat, men har en begrunnelse i at studenter lett får et rent teknisk forhold til statistikk og mister lett blikket for hvordan det skal brukes til noe substansielt. Det samme gjelder hvilken rolle det spiller for tolkning hvordan dataene ble til. Dette kapittelet har altså som funksjon å synliggjøre noen mer prinsippielle perspektiver på dataanalyse og hvordan det skal brukes.\nDette kapittelet er inkludert først og fremst fordi det ofte ikke er fremstilt på denne måten i lærebøker. Jeg støtter meg på andres arbeid her, men setter det sammen i en mer samlet fremstilling."
  },
  {
    "objectID": "index.html#hvorfor-r-egentlig",
    "href": "index.html#hvorfor-r-egentlig",
    "title": "Veldig praktisk dataanalyse med R",
    "section": "Hvorfor R, egentlig?",
    "text": "Hvorfor R, egentlig?"
  },
  {
    "objectID": "regsjonsanalyse_tolkning.html#hva-er-regresjon",
    "href": "regsjonsanalyse_tolkning.html#hva-er-regresjon",
    "title": "1  Sosiologisk teori og regresjonsanalyse",
    "section": "1.1 Hva er regresjon?",
    "text": "1.1 Hva er regresjon?\nEnhver lærebok vil kunne gi en teknisk forklaring på hva regresjonsanalyse er, men det er verd å ta et litt mindre teknisk perspektiv i dette kapittelet.\nEn regresjonsmodell er typisk på formen\n\\[ f(y) = g(x) \\] der altså utfallsvariabelen, \\(y\\), er en funksjon av en eller flere forklaringsvariable, \\(x\\). Denne funksjonen av \\(x\\) vil ofte ha en lineær spesifikasjon av typen $ g(x) = + X + $, men kan også være ikke-lineær på ulikt vis eller inneholde en rekke ekstra og kompliserende ledd.\nDet viktige her er at en regresjonsmodell - uansett hvilke statistiske krumspring som ellers gjøres - først og fremst beskriver hvordan utfallsvariabelen \\(y\\) varierer med prediktorene \\(x\\). Vi kan også kalle dette den betingede fordeling av \\(y\\). Oftest er det hvordan gjennomsnittet av \\(y\\) som beskrives.\nDermed er også en regresjonsmodell av denne typen en oppsummering av noen hovedtrender i dataene. Regresjonsparametrene \\(\\beta\\) beskriver disse trendene, først og fremst hvor mye \\(y\\) endrer seg når \\(x\\) endrer seg. For kategoriske \\(x\\) kan man si at \\(\\beta\\) beskriver forskjell i \\(y\\) mellom gruppene i \\(x\\).\nDet er ikke så mye mer, egentlig. Det er ingenting i det tekniske ved regresjonsanalysen som sier noe som helst om effekter. Det er heller ingenting i dette som sier noe om hvorvidt resultatene generaliserer til andre data eller settinger. Hvorvidt disse tolkningene er rimelige (effekter eller generalisering) avhenger av hvordan dataene ble til. Eller sagt på en annen måte: tolkningen avhenger av hva som var forskningsdesignet i utgangspunktet.\nUansett hvilke data man analyserer kan man gjøre regneøvelser om standardfeil og teste signifikans osv. Standard lærebøker vil presentere dette som hypotesetesting der man først formulerer en null-hypotese og en alternativ hypotese, så gir f.eks. en t-test svaret på hvilken av disse man bør velge. Denne formen for hypotesetesting er imidlertid ikke i seg selv en test av substansiell teori (f.eks. sosiologisk teori) på noen meningsfull måte. For at en statistisk test av en regresjonsparameter skal være informativ om substansiell teori må medfølge en teoretisk argument om hvorfor akkurat denne parameteren er informativ. Sagt på en annen måte: det kreves informasjon fra utenfor data som gir resultatet mening.\nVi står altså i en situasjon der tolkningen av data i moderat grad er avhengig av data, men av informasjon utenfor data."
  },
  {
    "objectID": "regsjonsanalyse_tolkning.html#tre-nivåer-av-regresjonanalyse",
    "href": "regsjonsanalyse_tolkning.html#tre-nivåer-av-regresjonanalyse",
    "title": "1  Sosiologisk teori og regresjonsanalyse",
    "section": "1.2 Tre nivåer av regresjonanalyse",
    "text": "1.2 Tre nivåer av regresjonanalyse\nRichard Berk beskriver i sin lærebok tre nivåer av regresjonsanalyse basert på hvordan dataene ble til. Dette er et godt utgangspunkt som burde klargjøre betydelig, i hvert fall som et først skritt.\n\n1.2.1 Nivå I: Ikke tilfeldig utvalg fra en veldefinert populasjon\nGrunnlaget for statistisk tolkning (sannsynligheter, p-verdier og sånn) er at dataene er en tilfeldig realisering av en underliggende sann verdi. Typisk betyr dette bare at man har trukket et tilfeldig utvalg fra en populasjon. Da vil man få et godt mål på f.eks. gjennomsnittsverdi i populasjonen, men på grunn av tilfeldighet vil det være en feilmargin på denne målingen.\nDet avgjørende er altså at det finnes en veldefinert populasjon som det kan generaliseres til. Grunnen til å bruke begrepet veldefinert er at det må være rimelig spesifisert.\nHvis dataene ikke er fra en veldefinert populasjon kalles dette noen ganger for convenience sample. Altså, at man gjorde et uttrekk av beleilighetsgrunner, men uten at det var en veldefinert populasjon.\nEt eksempel kan være en arbeidsmiljøundersøkelse i en bestemt bedrift. Det skal litt til at disse resultatene skal gjelde utover denne bedriften. Man kan selvsagt argumentere for at erfaringene gjelder med generelt, men en slik slutning vil da hvile først og fremst på disse argumentene - ikke på statistiske utregninger.\nDet kan være veldig nyttig å analysere slike data, og det kan bringe innsikt og kunnskaper. Men med slike data gir det ikke mye mening å regne på statistisk usikkerhet. Hvis man ikke skal si noe utover de dataene man har (ikke generalisere), så er det heller ikke denne typen usikkerhet i målingene.\nSlike ikke-tilfeldige utvalg kan betraktes nærmest som case-studier. En dataanalyse vil gi oss kunnskaper om de erfaringene som gjøre akkurat der. Størrelsen på datasettet kan gi oss mer pålitelig informasjon om dette caset, men hjelper ikke for å generalisere utover caset.\n\n\n1.2.2 Nivå II: Tilfeldig utvalg fra en veldefinert populasjon\n\n\n1.2.3 Nivå III: Estimering av kausale effekter\nFra et teknisk perspektiv er det ingenting som skiller studier av eksperimenter fra observasjonsstudier. De samme regresjonsmodellene kan estimeres og de samme utregningene av usikkerhet. Hva som bestemmer tolknigen (og hvorvidt modellspesifikasjonen er rimelig etc) avhenger av forskningsdesignet. Kort sagt kreves det et eksperiment. Hvis man har en treatment-gruppe og en kontrollgruppe, så vil \\(\\beta\\) beskrive forskjellen mellom disse gruppene som i andre typer data. Det som gir \\(\\beta\\) en kausal tolkning er om dataene tilfredsstiller kravene til et eksperiment.\n\n\n1.2.4 Oppsummerende og et nivå IV:\nI Berk sin fremstilling av de tre nivåene får man en følelse av at den vitenskapelige verdien øker ved hvert nivå. Mange vil da også mene akkurat det. Men logisk sett er det litt mer tvetydig enn som så.\nVi har snakket om to dimensjoner: kausalitet (ja/nei) og generalisering (ja/nei). Dette gir fire logisk mulige kombinasjoner.\n\n\n\nTable 1.1: Nivåer av regresjonsanalyse og hvor vanlige de er\n\n\n\n\n\n\n\n\nIkke tilfeldig utvalg fra veldefinert populasjon\nTilfeldig utvalg fra veldefinert populasjon\n\n\n\n\nDeskriptiv\nOverraskende mange\nDet aller meste\n\n\nKausal\nMye, men burde nok vært mer\nGanske sjelden\n\n\n\n\nJeg har ingen empiri for å si hvor vanlig hver enkelt type analyse er. Men jeg tror det nokså omtrentlige angivelsen i tabellen er ganske riktig, basert på egen erfaring fra studier jeg har lest og presentasjoner jeg har sett.\nI Berk sin fremstilling er Nivå III hele nederste rad, men da er det altså ikke gjort skille mellom om resultatene kan generaliseres videre eller ikke. Et slik skille bør man nok gjøre.\nEksperimenter omtales noen ganger - og i noen fagmiljøer - som gullstandarden. Men altså: ethvert eksperiment kan ikke være en gullstandard, ikke engang når formålet er å estimere kausaleffekter. Nivå IV er i så fall det vi ser etter, og ikke nivå III.\n\n\n1.2.5 Estimere effekter og forklare sammenhenger\nMange diskusjoner om kvantitative metoder og hva som er godt og dårlig ender opp i en diskusjon om kausalitet, og da spesifikt i rammeverket som har utgangspunkt i et kontrafaktisk perspektiv. Man sammenligner det som har skjedd med det som ville skjedd hvis noe annet ikke hadde skjedd. Det er altså den eksperimentelle metode, inkludert kvasi-eksperimentelle design.\nMerk at i det ovenstående er det understreket at det er hvordan dataene har blitt til som er bestemmende for hvordan resultatene kan tolkes. For at et estimat skal tolkes kausalt kreves det et eksperiment. Dette burde egentlig være ukontroversielt.\nDet som av noen blir omtalt som kontrollvariabelmetoden er en dårlig erstatning for et kausalt design. Logikken er at man kan eliminere betydningen av andre observerte kjennetegn (dvs variable), så kan den gjenstående “effekten” i hvert fall ikke skyldes seleksjon på de variablene man har kontrollert for. Dette leder lett til å tro at hvis man bare kontrollerer for så mye som mulig, så kommer man stadig nærmere en kausal effekt.\nDet nokså åpenbare problemet med en slik strategi er at det finnes en uendelig mengde faktorer det kan være seleksjon på, og den gjenstående “effekten” kan fremdeles være spuriøs. Kontrollvariabelmetoden er altså en dårlig strategi hvis man ønsker et kausalt estimat. Det man derimot kan gjøre - med hell - er å beskrive noen sammenhenger og utelukke noen alternative forklaringer. Hvorvidt dette er en god strategi vil da avhenge av det teoretiske argumentet som begrunner analysen.\nMen det er ikke alltid målet er estimere en effekt selv om den underliggende interessen er i en effekt. Man kan ha en teori som forklarer hvordan \\(X\\) påvirker \\(Y\\) uten at en kausal faktor lar seg estimere direkte. Eller i hvert fall ikke med de dataene man har. Dette er noe annet enn statistisk tolkning, men er en substansiell tolkning som går utover det data kan si i seg selv. Det man kan oppnå er å si om data er konsistent med teorien, eller om man kan avvise teorien, eller sannsynliggjøre teorien."
  },
  {
    "objectID": "regsjonsanalyse_tolkning.html#to-nivåer-av-teoretisering-bakover-og-forover",
    "href": "regsjonsanalyse_tolkning.html#to-nivåer-av-teoretisering-bakover-og-forover",
    "title": "1  Sosiologisk teori og regresjonsanalyse",
    "section": "1.3 To nivåer av teoretisering: bakover og forover",
    "text": "1.3 To nivåer av teoretisering: bakover og forover\nGelman & … diskuterer kausaleffekter spesifikt, men argumentet gjelder mer generelt:\n\n1.3.1 Bakover: Hvordan kan det ha seg??\nNoen ganger er utgangspunktet et empirisk fenoment og man søker forklaring på hvordan det kan ha seg at det ble slik. Utfallet er altså allerede gitt og jobben må bestå i å nøste seg bakover for å finne en forklaring på hvorfor det ble slik.\n\n\n1.3.2 Forover: Hva skjer hvis…??\nNoen ganger er spørsmålet mer om hva som skjer hvis man endrer på forholdene. Dette er normalsituasjonen for enhver byråkrat eller politiker som skal iverksette noe - som de jo håper løser et problem eller gjør noe bedre. Det finnes da ingen vei utenom enn å gjøre endringen og undersøke hva som skjer. Forskerens jobb er da å estimere effekten på en slik måte at man kan utelukke at endringen skyldes helt andre ting."
  },
  {
    "objectID": "regsjonsanalyse_tolkning.html#substansiell-teori---er-det-gjort-en-test",
    "href": "regsjonsanalyse_tolkning.html#substansiell-teori---er-det-gjort-en-test",
    "title": "1  Sosiologisk teori og regresjonsanalyse",
    "section": "1.4 Substansiell teori - er det gjort en test?",
    "text": "1.4 Substansiell teori - er det gjort en test?\nMan ser ganske ofte både studentarbeider og vitenskapelige publikasjoner som setter opp formelle hypoteser om hva de forventer å finne. Gjerne skrives det på formen\n\n\\(H_1\\): Det er en positiv sammenheng mellom \\(X\\) og \\(Y\\).\n\n\n\n\\(H_2\\): Sammenheng mellom \\(X\\) og \\(Y\\) er sterkere for gruppe \\(Z_1\\) enn gruppe \\(Z_2\\).\n\nDette ligner tilforlatelig på slik man lærer å sette opp null-hypoteser og alternative hypoteser i standard kurs i statistikk. Hvis null-hypotesen ikke er oppgitt, så er det implisitt at det ikke er en slik sammenheng - altså negasjonen.\nDette er greit nok og er en tydeliggjøring av de forventningene forskeren har. Men det er ikke i seg selv en test av substansiell teori. For å skjønne dette må vi ta en liten runde på hva det vil si å teste en teori.\n\n1.4.1 Severe testing\nMayo viser til det Popperske perspektivet på falsifisering. Logisk sett er det umulig å verifisere1 en teori. Derimot går det an å\n\nSeverity Requirement (weak): One does not have evidence for a claim if nothing has been done to rule out ways the claim may be false. If data \\(X\\) agree with a claim \\(C\\) but the method was practically incapable of finding flaws with \\(C\\) even if they exist, then \\(X\\) is poor evidence for \\(C\\).\n\n\nSeverity (strong): We have evidence for a claim \\(C\\) just to the \\(C\\) extent it survives a stringent scrutiny. If \\(C\\) passes a test that was highly capable of finding flaws or discrepancies from \\(C\\), and yet none or few are found, then the passing result, \\(X\\), is an indication of, or evidence for, \\(C\\).\n\nDet er mye mer å si om dette, men la i hvert fall én ting være klart: Det kreves vesentlig mer enn å teste hvorvidt en \\(\\beta\\) i en regresjon er statistisk signifikant eller ikke.\nSvært mange empiriske studier som påstår at de tester en teori, men i praksis ikke viser annet enn at empirien er konsistent med teorien, uten at det er åpenbart at fremgangsmåten kunne vist noe annet. Slike studier er rett og slett ikke en test.\nDette gjelder altså for både deskriptive og kausale studier. En pålitelig estimert kausaleffekt som er konsistent med det teorien tilsa er ikke i seg selv veldig interessant. Det er selvsagt godt å vite at teorien er konsistent med den empiriske verden. Det samme gjelder for deskriptive funn.\nEn mulig løsning er selvsagt å fortegne andre teorier og tilbakevise en stråmann. Det kan se fint ut, men er ikke et virkelig bidrag.\nMen igjen: rene deskriptive studier er også viktige i seg selv. Problemet oppstår først og fremst når man tolker resultatene langt videre enn det er grunnlag for. Det gjelder enten det er snakk om generalisering, kausalitet eller substansiell teori."
  },
  {
    "objectID": "regsjonsanalyse_tolkning.html#eksplorerende-og-konfirmerende-analyser",
    "href": "regsjonsanalyse_tolkning.html#eksplorerende-og-konfirmerende-analyser",
    "title": "1  Sosiologisk teori og regresjonsanalyse",
    "section": "1.5 Eksplorerende og konfirmerende analyser",
    "text": "1.5 Eksplorerende og konfirmerende analyser\nKonfirmerende analyser tilsier i stor grad teoritesting som beskrevet ovenfor. Det krever altså spesifikke hypoteser, som ikke bare er tydelig på teoretiske hypoteser, men også hvordan det skal estimeres.\n\n1.5.1 Eksplorerende analyser\nEksplorerende analyser har per definisjon ikke som formål verken å estimere effekter eller teste teorier. Her handler det om å “røre rundt i gryta” og se hva som dukker opp.\n\n\n1.5.2 Replikasjon på nye data\nEksplorerende analyser har det problemet at når man fisker rundt etter sammenhenger, så er det vanskelig å vite hva som er tilfeldigheter og hva som er systematisk. Her vil nettopp ikke statistiske tester være til hjelp fordi man allerede har brutt forutsetningene for de statistiske testene! Altså: Hvis man gjør mange tester må vi forvente av 5% av dem er statistisk signifikante med \\(p < 0.05\\) og hvis man bare presenterer disse, så er man på ville veier.\nMen eksplorerende analyser kan absolutt være hypotesegenererende og etterfølges av konfirmerende studier. Faktisk bør de jo det."
  },
  {
    "objectID": "regsjonsanalyse_tolkning.html#policy-implications",
    "href": "regsjonsanalyse_tolkning.html#policy-implications",
    "title": "1  Sosiologisk teori og regresjonsanalyse",
    "section": "1.6 Policy implications",
    "text": "1.6 Policy implications\nI et annet arbeid beskriver Berk eksperimenter som “the bronze standard”, men medet tilleggsargument at det ikke er noen på øvrige pallplasser: ingen får gull og søv.\nCartwright & Hardie beskriver i boken “Evidence-Based Policy. A Practical Guide to Doing It Better.” noen grunnleggende utfordringer for hva som er er politikk-implikasjoner.\nHusk nivå-IV av regresjonsanalyse: Hvis en kausal effekt gjelder for en veldefinert populasjon og setting, så vil vi kunne forutsi hva som vil kunne skje når man implementerer et tilsvarende tiltak i en slik setting eller populasjon."
  },
  {
    "objectID": "innlesning_data.html#mest-vanlige-dataformater-for-r",
    "href": "innlesning_data.html#mest-vanlige-dataformater-for-r",
    "title": "2  Innlesning av data",
    "section": "2.1 Mest vanlige dataformater for R",
    "text": "2.1 Mest vanlige dataformater for R\n\n2.1.1 csv-filer\n\n\n2.1.2 rds\n\n\n2.1.3 Varianter: qs, fst og slikt\n\n\n2.1.4 Excel"
  },
  {
    "objectID": "innlesning_data.html#laste-workspace-med-load",
    "href": "innlesning_data.html#laste-workspace-med-load",
    "title": "2  Innlesning av data",
    "section": "2.2 Laste workspace med load()",
    "text": "2.2 Laste workspace med load()"
  },
  {
    "objectID": "innlesning_data.html#ssbs-statistikkbank-bruk-api",
    "href": "innlesning_data.html#ssbs-statistikkbank-bruk-api",
    "title": "2  Innlesning av data",
    "section": "2.3 SSBs statistikkbank: bruk API",
    "text": "2.3 SSBs statistikkbank: bruk API"
  },
  {
    "objectID": "innlesning_data.html#import-format-fra-andre-statistikkpakker",
    "href": "innlesning_data.html#import-format-fra-andre-statistikkpakker",
    "title": "2  Innlesning av data",
    "section": "2.4 Import format fra andre statistikkpakker",
    "text": "2.4 Import format fra andre statistikkpakker\n\n2.4.1 Stata\n\n\n2.4.2 Spss\n\n\n2.4.3 SAS"
  },
  {
    "objectID": "innlesning_data.html#arrow-store-filer-og-mer",
    "href": "innlesning_data.html#arrow-store-filer-og-mer",
    "title": "2  Innlesning av data",
    "section": "2.5 Arrow: store filer og mer",
    "text": "2.5 Arrow: store filer og mer\nHvis du har skikkelig store datafiler kan du få noen praktiske problemer. En ting er at dataene er lagret i minnet på datamaskinen, men det kan uansett ta lang tid å lese dataene inn. Arrow-pakken gjør R i stand til å lese filer i formatene parquet og feather, samt rask innlesning av csv-filer.\nHvis du jobber med registerdata (som en del samfunnsvitere gjør) så kan dette være formater du har nytte av."
  },
  {
    "objectID": "innlesning_data.html#håndtere-metadata-med-lookup-tabeller",
    "href": "innlesning_data.html#håndtere-metadata-med-lookup-tabeller",
    "title": "2  Innlesning av data",
    "section": "2.6 Håndtere metadata med lookup tabeller",
    "text": "2.6 Håndtere metadata med lookup tabeller\nhttps://www.infoworld.com/article/3323006/do-more-with-r-quick-lookup-tables-using-named-vectors.html"
  },
  {
    "objectID": "innlesning_stata.html#håndtering-av-innebygde-metadata",
    "href": "innlesning_stata.html#håndtering-av-innebygde-metadata",
    "title": "3  Spesielt om data fra Stata og SPSS",
    "section": "3.1 Håndtering av innebygde metadata",
    "text": "3.1 Håndtering av innebygde metadata\nI samfunnsvitenskap er det dataformatene til softwaren SPSS og Stata ganske vanlig rett og slett fordi mange bruker disse softwarene. Antakeligvis er det grunnen til at Sikt (tidliger NSD), som er en stor leverandør av data til samfunnsvitenskapen, ofte leverer data i nettopp disse formatene SPSS eller Stata.\nDette er proprietære formater som i utgangspunktet krever lisens for å lese, men R kan lese disse med funksjoner i pakken {haven}. Så det er ikke her utfordringen ligger.\n\n3.1.1 Variabler med labler\nEn type data som er mye brukt i samfunnsvitenskapen er surveydata, altså: data innhentet ved hjelp av spørreskjema. Slike data inneholder gjerne en god del kategoriske data eller man svarer på en likert-skala (f.eks. skala fra 1 til 5), men også kontinuerlige variable og kan også være tekstsvar.\nSlike data er ofte kodet slik at bestemte verdier har en tekstlig betydning. F.eks. 1 = “gift” og 2 = “ugift”, eller 1 = “veldig fornøyd” og 5 = “veldig misfornøyd” osv.\nBrukere av SPSS og Stata vil ofte lagre denne typen metadata i selve dataformatet med såkalte labler.\nDette kan være at selve variabelnavnet er ganske kryptisk, men har metadata som sier hva variabelen inneholder. I surveydata vil dette typisk være hele spørmålet som er stilt til respondendene. Tilsvarende vil svarverdiene være numeriske og ha tilknyttet en tekststreng som er hele svaralternativet fra spørreskjemaet. Dette er forsåvidt ikke så dumt, men i R ville man gjort dette på en annen måte, typisk med å lagre teksten direkte eller gjøre om til variabeltypen factor som ligner en del.\nSurveydata vil imidlertid ofte inneholde relativt lange tekstverdier som gjør det tungvint. Men det finnes løsninger. For å gjøre en lang historie kort: Surveydata er best å håndtere med pakkene {labelled}. For videre analyser er det derimot vanligvis best å ha faktor-variable, så vi vil oftest konvertere dataene etter at de er lest inn i R. Det høres tungvindt ut, men konverteringen er bare et par linjer kode.\nR har en rekke funksjoner for å jobbe med labelled data fra SPSS og Stata direkte. Men siden dette generelt er fremmede formater i R vil det være en del analysefunksjoner som ikke er laget for å håndtere dette og du kan lett få andre resultater enn du forventer av den grunn. Det bester er derfor å bruke disse funksjonene til å gjøre om til et ordinært R-format.\n\n\n3.1.2 Missingverdier\nI alle typer data og dataformater kan det være at man mangler informasjon. I surveydata vil det f.eks. være at noen spørsmål bare blir stilt til de som svart på et annet spørsmål eller noen vil ikke svare. I R angis manglende verdier med NA (“not available”). Det er også vanlig å kalle manglende verdier for missing, som betyr det samme. Hvis det er spesielle grunn til manglende informasjon, så vil man ha den informasjonen i en annen variabel og/eller fremkomme av dataenes dokumentasjon.\nEn spesiell utfordring er at i SPSS og Stata er det også mulig å bruke “user-defined missing-values”. Mange datasett dermed inneholde spesielle verdier som skal tolkes som manglende data, såkalt ‘missing’. Dette er egne koder som kan bety at respondenten ikke fikk stilt spørsmålet, ikke ville svare, eller andre grunner. For en variabel for inntekt kan f.eks. verdien 999999 betyr at vedkommende ikke ville svare. Når vi regner et gjennomsnitt er det da viktig at akkurat disse verdiene ikke inngår i beregningen.1\nEt eksempel er dokumentasjonen for den norske studien NorLAG følgende om missingverdier:\n\n\n\nNorlag missingverdier\n\n\nDette innebærer f.eks. at når man lager en frekvenstabell vil man få ut frekvenstabell for både gyldige verdier og missingverdier, men prosentuering vil bare være for de gyldige verdiene. Gitt at funksjonen støtter dette formatet, vel å merke. Hvis dette ikke er kodet riktig i datasettet vil missingverdiene kunne påvirke beregninger av gjennomsnitt vesentlig."
  },
  {
    "objectID": "innlesning_stata.html#løsning-fiks-alt-i-en-fei",
    "href": "innlesning_stata.html#løsning-fiks-alt-i-en-fei",
    "title": "3  Spesielt om data fra Stata og SPSS",
    "section": "3.2 Løsning: Fiks alt i en fei",
    "text": "3.2 Løsning: Fiks alt i en fei\nFor å gjøre en lang historie kort, så trenger vi å fikse en del ting når vi leser inn data fra formater som Stata og SPSS. Den etterfølgende koden fikser følgende for hele datasettet, og eksempelet er ved bruk av NorLAG-dataene.\nHer er det brukt Stata-formatet. Ovenfor sier dokumentasjonen av NorLAG at Stata-formatet har egne missing-verdier som .a, .b osv. Pussig nok er det datasettet som ble brukt her ikke slik, men inneholder de missingverdiene som er spesifisert for SPSS. Slikt kan skje, og det er ekstremt viktig at man sjekker datasettet for å se om slike ting er akkurat slik som dokumentasjonen sier!\nSå da viser eksempelet nedenfor hvordan vi håndterer med disse angitte missing-verdiene. Det blir tilsvarende hvis andre verdier er brukt, så det skulle ikke spille noen rolle.\n\nnorlag <- read_stata(\"data/norlag_panel2022.dta\") %>% \n    mutate(across( where(is.labelled) ,  ~replace(., \n                                        . %in% c(997, 998, 999, 99999, 999999), \n                                        NA))) %>%\n  drop_unused_value_labels() %>% \n  unlabelled()\n\nKoden ovenfor kan være litt vanskelig å tolke for den uerfarne, men her er forklaringen med angitt hvilke linjer som gjør hva:\n\nLese inn data fra Stataformat (linje 1)\nGjøre om koder som indikerer spesielle missing-verdier til NA (linje 2-4)\nFjerne de nå ubrukte label-nivåene (jf. forrige punkt) (linje 5)\nGjøre om alle labelled-variable til factor (linje 6)\n\nEt viktig moment her er at denne koden omkoder alle variable i datasettet. Det er også viktig å fjerne missing-verdier før man gjør om til factor fordi hvis ikke blir missing-verdiene til egne factor-nivåer. Missing-kodene brukes på både kontinuerlige og kategoriske variable, men vi må stole på at dokumentasjonen stemmer og at disse verdiene brukes konsekvent på alle variable uansett type (hvis ikke annet er angitt).\nFor de som ønsker (eller trenger) å vite mer vil logikken forklares i de etterfølgende kapitlene. Resultatet er nå at du skal ha fått et datasett der alle missing-verdier er omkodet til NA, og alle variable med labler (dvs. kategoriske variable) er omkodet til factor-variable."
  },
  {
    "objectID": "innlesning_stata.html#detaljert-gjennomgang",
    "href": "innlesning_stata.html#detaljert-gjennomgang",
    "title": "3  Spesielt om data fra Stata og SPSS",
    "section": "3.3 Detaljert gjennomgang",
    "text": "3.3 Detaljert gjennomgang\n\n3.3.1 Innlesning med {haven}\nFormatene Stata, SPSS og SAS er proprietære og man trenger i utgangspunktet disse softwarene for å åpne datafilene (og betale dyr lisens). For å lese inn i R kan man bruke pakken {haven} som inneholder spesialiserte funksjoner for å lese inn disse formatene. Funksjonen read_stata() leser inn dataene på en måte som bevarer særegenhetene fra Stata-formatet.\n\nnorlag <- read_stata(\"data/norlag_panel2022.dta\", encoding = \"utf8\") \n\nMerk at objektet norlag vil være av typen tibble og variablene vil være labelled. Med glimpse() og selektere bare de 10 første variablene får vi følgende output:\n\nglimpse(norlag[,1:10])\n\nRows: 33,084\nColumns: 10\n$ ref_nr        <dbl> 5, 5, 5, 10, 10, 10, 12, 12, 12, 15, 15, 15, 18, 18, 18,…\n$ round         <dbl> 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1,…\n$ iointervjumnd <dbl+lbl>      5,     11, 999999,      5,      5,      5,     …\n$ iointervjuyr  <dbl+lbl>   2002,   2007, 999999,   2002,   2007,   2017,   20…\n$ ioalder       <dbl+lbl>     68,     72, 999999,     44,     49,     59,     …\n$ iolandb       <dbl+lbl>      1,      1,      1,      1,      1,      1,     …\n$ iolandb3      <dbl+lbl>     NA,     NA, 999999,      1,      1,      1,     …\n$ iosvar        <dbl+lbl>      1,      1, 999999,      1,      1,      1,     …\n$ iofodselsyr   <dbl> 1934, 1934, 1934, 1957, 1957, 1957, 1955, 1955, 1955, 19…\n$ iokjonn       <dbl+lbl> 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1…\n\n\nMerk at variabeltypene her er enten kontinuerlige, <dbl>, eller kontinuerlige med labler, <dbl+lbl>. Det er også verd å merke seg at kategoriske variable som kjønn er kontinuerlig med labler. Også alder er kontinuerlig med labler, men her er nok lablene knyttet til missing-verdier siden alder her er tall.\nDet kan være greit å vite at det er noen flere argumenter i innlesningen. Noen ganger får man problemer med æøå, og da kan man spesifisere tegnsetting med `encoding = “utf8” som gjort over. Men oftest vil man ikke trenge akkurat det.\n\n\n3.3.2 Omkode variable som er labelled\nNoen ganger vil vi omkode en variabel. Et eksempel er variabelen he104. Her er innholdet i den variabelen.\n\nmemisc::codebook(norlag$he104)\n\n================================================================================\n\n   norlag$he104 'Hvordan vil du beskrive din økonomiske situasjon nå'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: double\n   Measurement: undefined\n\n   Values and labels                                           N Percent\n                                                                        \n        1 'Veldig romslig'                                  1425     4.3\n        2 'Romslig'                                         8039    24.3\n        3 'Må være forsiktig, men klarer meg'               5152    15.6\n        4 'Problemer med å få pengene til å strekke til'     551     1.7\n        5 'Svært vanskelig økonomisk situasjon'              164     0.5\n      999 'Mangler data'                                     403     1.2\n    99999 'Ikke svart post/web-skjema'                      5158    15.6\n   999999 'Deltok ikke i runden'                           12192    36.9\n\n\nLegg merke til at de tre nederste verdiene egentlig er varianter av å mangle data. Disse verdiene skal normalt ikke være med i en videre analyse, men er “missing”. Vi bør fortelle R at disse verdiene ikke skal tas med videre ved å omkode til NA.\nFølgende kode gjør en omkoding til NA. I eksempelet har jeg lagt inn linjeskift for mutate() for å tydeliggjøre de ulike delene.\n\nFørste linje lager en ny variabel he104b som skal inne en kopi av he104. Funksjonen replace() tar så utgangspunkt i variabelen he104, og de verdiene som ikke er angitt at skal byttes ut vil beholdes fra denne.\n\nAndre linje sier at hvis variabelen he104 er en av verdiene 999, 99999, eller 999999, så…\nsier tredje linje at da skal de få verdien NA i stedet.\n\n\nnorlag %>% \n  mutate(he104b = replace(he104, \n                         he104 %in% c(999, 99999, 999999), \n                         NA)) %>%  \n    select(he104b) %>% \n  memisc::codebook()\n\n================================================================================\n\n   he104b 'Hvordan vil du beskrive din økonomiske situasjon nå'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: double\n   Measurement: undefined\n\n   Values and labels                                           N Valid Total\n                                                                            \n        1   'Veldig romslig'                                1425   9.3   4.3\n        2   'Romslig'                                       8039  52.4  24.3\n        3   'Må være forsiktig, men klarer meg'             5152  33.6  15.6\n        4   'Problemer med å få pengene til å strekke til'   551   3.6   1.7\n        5   'Svært vanskelig økonomisk situasjon'            164   1.1   0.5\n      999   'Mangler data'                                     0   0.0   0.0\n    99999   'Ikke svart post/web-skjema'                       0   0.0   0.0\n   999999   'Deltok ikke i runden'                             0   0.0   0.0\n       NA M                                                17753        53.7\n\n\nLegg merke til at output nå har de omtalte verdiene 0 observasjoner, men lablene finnes i variabelen likevel! Lablene eksisterer altså uavhengig av verdiene i variabelen, men det har kommet en linje til med verdien NA. Det er det det ble omkodet til. Nå trenger vi jo ikke de lablene vi omkodet, så de kan fjernes helt. Funksjoen drop_unused_value_labels() gjør akkurat det det høres ut som. Her er et eksempel:\n\nnorlag %>% \n  select(he104) %>% \n  mutate(he104 = replace(he104, \n                         he104 %in% c(999, 99999, 999999), \n                         NA)) %>%  \n  drop_unused_value_labels() %>% \n  memisc::codebook()\n\n================================================================================\n\n   he104 'Hvordan vil du beskrive din økonomiske situasjon nå'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: double\n   Measurement: undefined\n\n   Values and labels                                       N Valid Total\n                                                                        \n    1   'Veldig romslig'                                1425   9.3   4.3\n    2   'Romslig'                                       8039  52.4  24.3\n    3   'Må være forsiktig, men klarer meg'             5152  33.6  15.6\n    4   'Problemer med å få pengene til å strekke til'   551   3.6   1.7\n    5   'Svært vanskelig økonomisk situasjon'            164   1.1   0.5\n   NA M                                                17753        53.7\n\n\n\n\n3.3.3 Alternativ: legg til user-specified-na\nEn alternativ fremgangsmåte er mer slik man ville gjort i annen software ved at man definerer disse verdiene som “missing”, dvs NA. Funksjonen set_na_values() definerer hvilke verdier som skal regnes som NA, men uten å endre lablene eller kode om på annen måte.\n\nnorlag %>% \n  select(he104) %>% \n  set_na_values(he104 = c(999, 99999, 999999) ) %>% \n  memisc::codebook()\n\n================================================================================\n\n   he104 'Hvordan vil du beskrive din økonomiske situasjon nå'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: double\n   Measurement: undefined\n   Missing values: 999, 99999, 999999\n\n   Values and labels                                           N Valid Total\n                                                                            \n        1   'Veldig romslig'                                1425   9.3   4.3\n        2   'Romslig'                                       8039  52.4  24.3\n        3   'Må være forsiktig, men klarer meg'             5152  33.6  15.6\n        4   'Problemer med å få pengene til å strekke til'   551   3.6   1.7\n        5   'Svært vanskelig økonomisk situasjon'            164   1.1   0.5\n      999 M 'Mangler data'                                   403         1.2\n    99999 M 'Ikke svart post/web-skjema'                    5158        15.6\n   999999 M 'Deltok ikke i runden'                         12192        36.9\n\n\nI output står det nå en “M” mellom verdien og labelen, som angir at dette er “Missing”. I frekvenstabellen er det nå i prosentueringen skilt mellom Valid og Total, der missing altså ikke er regnet med blant gyldige verdier.\nMen det er ryddigst å fjerne disse missing-verdiene og sette de til NA. Funksjonen zap_na() gjør disse verdiene om til NA, altså omkoder alle missingverdiene til NA. Som i forrige variant vil da lablene fremdeles eksistere, men disse kan fjernes på samme måte med drop_unused_value_labels().\n\nnorlag %>% \n  select(he104) %>% \n  set_na_values(he104 = c(999, 99999, 999999) ) %>% \n  zap_missing() %>% \n  drop_unused_value_labels() %>% \n  memisc::codebook()\n\n================================================================================\n\n   he104 'Hvordan vil du beskrive din økonomiske situasjon nå'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: double\n   Measurement: undefined\n\n   Values and labels                                       N Valid Total\n                                                                        \n    1   'Veldig romslig'                                1425   9.3   4.3\n    2   'Romslig'                                       8039  52.4  24.3\n    3   'Må være forsiktig, men klarer meg'             5152  33.6  15.6\n    4   'Problemer med å få pengene til å strekke til'   551   3.6   1.7\n    5   'Svært vanskelig økonomisk situasjon'            164   1.1   0.5\n   NA M                                                17753        53.7"
  },
  {
    "objectID": "innlesning_stata.html#omkoding-av-andre-verdier",
    "href": "innlesning_stata.html#omkoding-av-andre-verdier",
    "title": "3  Spesielt om data fra Stata og SPSS",
    "section": "3.4 Omkoding av andre verdier",
    "text": "3.4 Omkoding av andre verdier\nVi starter med å lagre de endringene som ble testet ut over, og lagrer disse i et nytt datasett som kalles norlag2 som vi bruker videre i eksemplene.\n\nnorlag2 <- norlag %>% \n  select(he104) %>% \n  mutate(he104 = replace(he104, \n                         he104 %in% c(999, 99999, 999999), \n                         NA)) %>%  \n  drop_unused_value_labels()"
  },
  {
    "objectID": "innlesning_stata.html#konverter-variable-til-et-mer-ordinært-r-format",
    "href": "innlesning_stata.html#konverter-variable-til-et-mer-ordinært-r-format",
    "title": "3  Spesielt om data fra Stata og SPSS",
    "section": "3.5 Konverter variable til et mer ordinært R-format",
    "text": "3.5 Konverter variable til et mer ordinært R-format\nVi starter med å lagre en kopi av datasettet med endrede labler.\n\nnorlag3 <- norlag2 %>% \n  mutate(he104 = recode(he104, \n                          `1` = 2 ,\n                          `5` = 4,\n                        .combine_value_labels = TRUE) ) %>% \n  add_value_labels(he104 = c(\"Romslig/veldig romslig\" = 2, \n                             \"Problemer/store problemer\" = 4))\n\nMen hva skjer når vi skal lage en fin tabell? Vi prøver med {gtsummary} og tbl_summary().\n\nlibrary(gtsummary)\nnorlag3 %>% \n  tbl_summary(include = he104)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 33,0841\n    \n  \n  \n    Hvordan vil du beskrive din økonomiske situasjon nå\n\n        2\n9,464 (62%)\n        3\n5,152 (34%)\n        4\n715 (4.7%)\n        Unknown\n17,753\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nTabellen vises altså uten lablene! Noe av poenget med å ha labler var jo å at det skal syens… Siden mange funksjoner i R i utgangspunktet ikke er laget for labler er det rett og slett ikke støttet.\nMen vi kan gjøre om variabelen med as_factor(). Gjør om lablene til faktor-nivåer og så lage en tabell med den endrede variabelen. (OBS! funskjonen as_factor() gjør bare nesten det samme. as_factor() er laget bl.a. for å håndtere labler, mens as_factor() ikke gjør det).\n\nnorlag3 %>% \n  mutate(he104 = as_factor(he104)) %>% \n  gtsummary::tbl_summary(include = he104)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 33,0841\n    \n  \n  \n    Hvordan vil du beskrive din økonomiske situasjon nå\n\n        Romslig/veldig romslig\n9,464 (62%)\n        Må være forsiktig, men klarer meg\n5,152 (34%)\n        Problemer/store problemer\n715 (4.7%)\n        Unknown\n17,753\n  \n  \n  \n    \n      1 n (%)"
  },
  {
    "objectID": "innlesning_stata.html#hvordan-gjøre-alt-i-en-fei-alle-variable-samtidig",
    "href": "innlesning_stata.html#hvordan-gjøre-alt-i-en-fei-alle-variable-samtidig",
    "title": "3  Spesielt om data fra Stata og SPSS",
    "section": "3.6 Hvordan gjøre alt i en fei: alle variable samtidig",
    "text": "3.6 Hvordan gjøre alt i en fei: alle variable samtidig\nFor NorLAG er det noen missingverdier som er definert på tvers av hele datasettet. Se dokumentasjon her: https://norlag.nsd.no/filterverdier Å gjøre de operasjonene vi gjorde over for hver enkelt av de over 400 variablene er utrolig arbeidskrevende og drit kjedelig. Så det gidder vi ikke. Men å omkode alle variable i et helt datasett krever litt mer avanserte operasjoner. Her bruker vi across() som angir at vi skal gjøre samme operasjon på de nærere angitte variablene. Vi kan enten gi en liste med variabelnavn, eller sette et krav om at variablene skal være av en viss type, starte med visse bokstaver eller tegn osv. I eksempelet nedenfor angir vi bare at variabelene skal være av typen ‘labelled’, noe de aller fleste er. Missing-verdiene i datasettet er jo felles for alle variable, så da kan vi bruke replace() og sette disse til NA. Her er et eksempel:\n\nnorlag4 <- norlag %>% \n  mutate(across( where(is.labelled) ,  ~replace(., \n                                        . %in% c(997, 998, 999, 99999, 999999), \n                                        NA))) %>%  \n  drop_unused_value_labels()                                           \n\nI mutate-setningen skjer følgende:\n\nacross() sier at vi skal gjøre det samme for flere variable, spesifisert med where(is.labelled).\nfor disse skal vi bruke replace(), angitt ved ~replace()\ninni parentesen angis . som hver av de variablene som er plukket ut i across(). Så for disse variablene skal det byttes ut verdier\nneste linje starter med ., som igjen henviser til de samme variablen, og hvis de har en av de opplistede verdiene\ni så fall får de ny verdi NA\n\nDermed er samtlige labelled-variable omkodet på denne måten i en fei.\nDa kan vi lage en tabell på nytt. Her får vi samme problem med at lablene ikke synes, men missing-verdiene er i hvetr fall ryddet opp i.\n\nnorlag4 %>% \n  gtsummary::tbl_summary(include = he104)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 33,0841\n    \n  \n  \n    Hvordan vil du beskrive din økonomiske situasjon nå\n\n        1\n1,425 (9.3%)\n        2\n8,039 (52%)\n        3\n5,152 (34%)\n        4\n551 (3.6%)\n        5\n164 (1.1%)\n        Unknown\n17,753\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nVi kan selvfølgelig endre til factor som gjort over, men da får vi igjen et problem med å gjøre det en variabel om gangen. Igjen: det gidder vi ikke. I stedet bruker vi en enkel funksjon som fikser biffen for hele datasettet, nemlig unlabelled().\n\nnorlag4 %>% \n  unlabelled() %>% \n  gtsummary::tbl_summary(include = he104)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      N = 33,0841\n    \n  \n  \n    Hvordan vil du beskrive din økonomiske situasjon nå\n\n        Veldig romslig\n1,425 (9.3%)\n        Romslig\n8,039 (52%)\n        Må være forsiktig, men klarer meg\n5,152 (34%)\n        Problemer med å få pengene til å strekke til\n551 (3.6%)\n        Svært vanskelig økonomisk situasjon\n164 (1.1%)\n        Unknown\n17,753\n  \n  \n  \n    \n      1 n (%)\n    \n  \n\n\n\n\nOBS! Unlabelled endrer alle labelled-variablene. Det er ikke sikkert at vi vil det. Spesielt gjelder det at det kan være andre labler knyttet til variable som skal være kontinuerlige. Men: hvis man har gjort en god opprydning i datasetet i forkant, med de omkodinger som trengs (det må nok gjøres en for en variabel), så er dette ganske greit."
  },
  {
    "objectID": "oversikt_datasettet.html#søke-i-datasettet-etter-variable",
    "href": "oversikt_datasettet.html#søke-i-datasettet-etter-variable",
    "title": "4  Få oversikt over datasettet",
    "section": "4.1 Søke i datasettet etter variable",
    "text": "4.1 Søke i datasettet etter variable\nAlle datasett skal komme med en dokumentasjon som sier hva hver variabel inneholder og hvilke verdier som finnes i hver variable, og hva de betyr. Dette leveres gjerne som en separat fil, ganske ofte i pdf eller html format. NSD/Sikt leverer dokumentasjonen for Norlag i html-format. (Ideelt burde det vært i et enkelt maskinlesbart format egnet til å bruke til omkoding og labler for de som ønsker det, men de har valgt en annen løsning).\nDu kan søke i dokumentasjonen på samme måte som i andre filer, men det kan være litt knotete. Et godt alternativ er å søke direkte i datasettet. Funksjonen look_for() søker både i variabelnavn, verdier og labler. Her er et eksempel for hvordan finne variabler som inneholder ordet “yrkesinntekt”. Du kan også søke på kortere eller lengre tekststrenger. (Søker du f.eks. bare på “innt” eller “yrke” så får du opp langt flere variable, så du må kanskje prøve deg litt frem).\n\nlook_for(norlag, \"Yrkesinntekt\")\n\n pos variable       label                   col_type values                 \n 353 inwyrkinnt     Yrkesinntekter NorLAG ~ dbl+lbl  [-5000] Value <0 >-5000\n                                                     [5000] Value >0 <5000  \n                                                     [999999999] Mangler da~\n 371 inpartwyrkinnt Partner: yrkesinntekte~ dbl+lbl  [99999996] Filter: IO ~\n                                                     [99999999] Mangler data\n                                                     [999999999] Deltok ikk~\n\n\nDet er to variable som inneholder teksten “yrkesinntekt”. Den første variabelen har posisjon 353 i datasettet og har variabelnavnet inwyrkinnt. Den andre variabelen har posisjon 371 og har navnet inpartwyrkinnt. Vi fokuserer på den første.\nMerk at når labelen avsluttes med ~ (uttales “tilde”) indikerer det at teksten er avkortet i outputvinduet. Du får opp hele teksten ved å bruke val_label() slik:\n\nvar_label(norlag$inwyrkinnt)\n\n[1] \"Yrkesinntekter NorLAG longitudinell\""
  },
  {
    "objectID": "grafikk.html",
    "href": "grafikk.html",
    "title": "5  Grafikk",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.0     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 0.5.2\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nLes inn datasettet abu89.rds med følgende kommando:\n\nabu89 <- readRDS(\"data/abu89.rds\") \n\nLag et stolpediagram som viser antall menn og kvinner i datasettet med følgende kommando:\n\nggplot(abu89, aes(x=female))+\n  geom_bar()\n\n\n\n\nFor geom_bar() bruker ggplot automatisk antall for y-aksen hvis du ikke skriver noe annet. Merk at koden bare spesifiserer x-variabelen. Da antar ggplot at du vil ha antall observasjoner som høyde på stolpene. I det skjulte bruker ggplot en spesifikasjonen y = ..count.. som altså gir antallet.\n\nLag plottet på nytt med andeler ved å spesifisere y som ..prop.. og sette group = 1. aes( x = female, y = ..prop.., group = 1 )\nKanskje du heller vil ha prosent fremfor andeler? Prøv følgende: spesifiser y som y = ..prop..*100 og så endre tekst på y-aksen med labs(). Altså multiplisere andelen med 100.\n\nFor å lagre et plot til disk slik at du lett kan bruke det i f.eks. et Word dokument bruker vi funksjonen ggsave(). Inni parentesen skriver du filbanen der du vil lagre plottet, inkludert filhale for det formatet du vil bruke. Det mest praktiske vil ofte være png-format, så da slutter filnavnet på .png, så vil ggsave lagre i det formatet. Hvis du vil ha plottet i pdf-format lar du tilsvarende filnavnet slutte på .pdf.\nggsave() lagrer det plottet som er i plotvinduet i Rstudio hvis du ikke ber om noe annet. En bedre løsning er å legge hele plottet i et eget objekt og så angi det objektet i ggsave(). Noe slikt:\ndittplot <- ggplot(…) + …  ggsave(dittplot, filename = \"output/dittfilnavn.png\")\n\nLagre figuren til output-mappen i png-format med funksjonen ggsave() og gi filen et passende navn. For publisering kreves det ofte høy kvalitet på bildefilen, som spesifiseres med antall piksler angitt ved dpi. Forhåndsvalgt oppløsning for ggsave er dpi=300 som stort sett er tilstrekkelig. Hvis du trenger annen oppløsningen kan du spesifisere dpi høyere eller lavere.\nLag en høyoppløslig versjon ved å legge til dpi = 600 inni parentesen for ggsave() og gi filen et passende navn.\nLag en tilsvarende figur som i første oppgave, men nå for klassebakgrunn: Bruk samme kode, men bytt ut variabelen female med klasse89.\n\nI mange tilfeller vil dataene allerede være aggregert til en tabell. R vil ikke vite forskjell på dette av seg selv. Da må du spesifisere at y-variabelen er kolonnen med høyden på stolpen. Prøv med datasettet til eksempel 3 til kapittel 1 i læreboka: music <- read.csv(“data/chapter_1/eg01-03music.csv”)\n\nBruk ggplot som før, men med nye variabelnavn. For linjen med geom_bar() må du nå spesifisere at ggplot ikke skal regne ut noe selv slik den ellers gjør. geom_bar(stat = “identity”)\n\n1.5 Histogram 16. Bruk datasettet abu89 og lag et histogram som viser fordelingen av timelønn (time89). Tips: du må altså bytte ut variabelnavn og bruke en annen geom_*, nemlig geom_histogram() 17. Endre antall stolper ved å sette bins = og vurder om grover/fine inndeling er best. 18. Gjør om histogrammet til å vise tetthet ved å sette y = ..density.. 19. Legg til titler på aksene som du synes er best. 20. Gjør egne vurderinger på endelig utseende på Når du er fornøyd lagrer du plottet i output-mappen med et passende navn i png-format.\n1.6 Boksplot 21. Lag et boksplot for timelønn. Endre da koden ved å bruke geom_boxplot() i stedet for geom_histogram() som du brukte over. Men sett nå time89 som y i stedet for x. 22. Boksplot er mest interessant for å sammenligne grupper. Lag et boksplot for hver verdi av klasse. Inni aes() setter du x = klasse89.\n1.7 Tidsserieplot Noen data er tidsserier der vi ønsker å se utvikling over tid. Et dagsaktuelt tema er overdødelighet i ulike land i på grunn av Covid-pandemien. Prosjektet Human Mortality Database (https://www.mortality.org/ ) har laget et datasett som heter Short-term Mortality Fluctuations (STMF) som gir totale dødelighetsrater per uke fra år 2000 og fremover for 38 land. (I skrivende stund tilgjengelig frem til uke 43 i 2021). Et tilrettelagt datasett er lastet opp i Canvas med filnavnet stmf_prep.rds. Les inn datasettet med readRDS() og lagre det i et objekt stmf. For mer informasjon om datasettet, se hjemmesiden. Når man sammenligner total dødeligheten for land med tidligere år, så vil vi kunne se om siste år har en overdødelighet sammenlignet med disse. Datasettet inneholder tall for både totalt og for menn, kvinner, og ulike aldersgrupper per land. Det kan være lurt å ikke plotte alt på en gang. Lag først et plot for kun Norge siste to år. Bruk filter() til å velge begge kjønn, kun Norge og siste to år, og lagre det som et nytt objekt slik: nor <- stmf %>% filter(sex == “b”, age == “Total”, country_code == “NOR”, year >= 2020)\nDa kan du lage et linjediagram slik: ggplot(nor, aes(x = week, y = rate_total, col = as.factor(year))) + geom_line()\nMerk at fargen settes etter variabelen year, og den er satt som as.factor() for å markere at det er kategorisk og ikke kontinuerlig fargeskala. 23. Kan man si så mye om utviklingen? Hva bør man sammenligne med? 24. Hvorfor tror du det kan være lurt å se på total dødelighet fremfor døde direkte av Covid?\nJuster koden over slik at du får med alle år for Norge og lag linjediagrammet på nytt. I parentesen for aes() legger du til group = year for å få en linje per år. Uten det blir det bare tull. Variabel yr_ind er en kategorisk variabel for å markere årene 2020 og 2021. I aes() legger du også til color = yr_ind for å si at det skal være forskjellig farge etter denne indikatoren. Lag litt tykkere linjer ved å spesifisere size = .9 inni parentesen for geom_line(). Legg så til en ny linje (sett + før linjeskift) i koden for å bestemme fargene manuelt slik:\nscale_color_manual(values = c(“gray70”, “red”, “blue”), labels = c(“2000-2019”, “2020”, “2021”)) Du skal nå få et plot der alle årene før 2020 er grå, mens 2020 og 2021 er henholdsvis rød og blå. Argumentet labels = er til tegnforklaringen. 25. Hvordan har dødeligheten vært totalt i Norge i 2020 og 2021 sammenlignet foregående år? Kan du tenke deg noen grunner til dette resultatet? Nå kan du plotte flere land og sammenligne utviklingen. For å se hvilke som er tilgjengelige kjør følgende: unique(stmf$country_code) Juster koden du brukte til å lage datasettet for kun Norge slik at du får med fire valgfrie land. Du kan bruke %in% c(…) for velge flere verdier på landvariabelen. Her er et eksempel for å velge kun nordiske land: filter(country_code %in% c(“NOR”, “SWE”, “DNK”, “FIN”)) Nå kan du bruke samme kode for plottet, men legg til nederst (husk + før linjeskift) følgende: facet_wrap(~country_code) Denne koden gir et panel med et plot for hvert land slik at du lettere kan sammenligne. Hvis det er stor forskjell på nivået kan du la y-skalaen variere mellom landene ved å legge til scales = “free” inni parentesen for facet_wrap(). 26. Hvordan har dødeligheten vært i Norge under pandemien sammenlignet med de andre landende du valgte? 27. Gjør sammenligningen på nytt, men velg en annen aldersgruppe i stedet for totalt. 28. Bruk det du har lært om labs() og theme_*() til å gjøre plottet penere og lagre i output-mappen. Du kan også flytte tegnforklaringen ved å legge til følgende: theme(legend.position = “top”)"
  },
  {
    "objectID": "deskriptive_tabeller.html#manuelle-tabeller-med-dplyr",
    "href": "deskriptive_tabeller.html#manuelle-tabeller-med-dplyr",
    "title": "6  Deskriptive tabeller",
    "section": "6.1 Manuelle tabeller med {dplyr}",
    "text": "6.1 Manuelle tabeller med {dplyr}\nDet er ofte mer effektivt å jobbe med"
  },
  {
    "objectID": "deskriptive_tabeller.html#pakken-gtsummary",
    "href": "deskriptive_tabeller.html#pakken-gtsummary",
    "title": "6  Deskriptive tabeller",
    "section": "6.2 Pakken {gtsummary}",
    "text": "6.2 Pakken {gtsummary}"
  },
  {
    "objectID": "deskriptive_tabeller.html#pakken-datasummary",
    "href": "deskriptive_tabeller.html#pakken-datasummary",
    "title": "6  Deskriptive tabeller",
    "section": "6.3 Pakken {datasummary}",
    "text": "6.3 Pakken {datasummary}"
  },
  {
    "objectID": "deskriptive_tabeller.html#layout-med-gt",
    "href": "deskriptive_tabeller.html#layout-med-gt",
    "title": "6  Deskriptive tabeller",
    "section": "6.4 Layout med {gt}",
    "text": "6.4 Layout med {gt}\nPakken {gt} står for “grammar of tables” og er bygget opp som et eget språk"
  },
  {
    "objectID": "deskriptive_tabeller.html#eksport-til-ms-word",
    "href": "deskriptive_tabeller.html#eksport-til-ms-word",
    "title": "6  Deskriptive tabeller",
    "section": "6.5 Eksport til MS Word",
    "text": "6.5 Eksport til MS Word\nVi fokuserer her på eksport av resultater til tekstbehandlingsprogrammet Word. Grunnen er at dette er det mest brukte. R er også svært godt egnet til å eksportere til html, \\(\\LaTex\\) og annet, men de som bruker slike formater vil nok klare å finne ut av dette selv."
  },
  {
    "objectID": "omkode_factor.html#factorvariable-med-skikkelig-lang-tekst",
    "href": "omkode_factor.html#factorvariable-med-skikkelig-lang-tekst",
    "title": "7  Omkoding av factor-variable",
    "section": "7.1 Factorvariable med skikkelig lang tekst",
    "text": "7.1 Factorvariable med skikkelig lang tekst\nNoen ganger har man et datasett som allerede er omgjort med factor-variable. Eller du har en eller annen grunn til å ikke gå tilbake til et tidligere steg for å omkode. Men du har factor-levels med skikkelig lang tekst kan det være noe drit å kode om. Kan man gjøre dette på en lurere måte? Minst mulig tårer? Ja, selvsagt.\nI NorLAG er variabelen wr117zz svar på et spørsmål om “Mulighet for å redusert arbeidstid (deltid)”. Når denne variabelen er gjort om til factor kan man se hvilke verdier variabelen har med bruke av funksjonen levels() slik:\n\nlevels(norlag$wr117zz)\n\n[1] \"Nei\"                                                               \n[2] \"Ja\"                                                                \n[3] \"filter: jobber deltid\"                                             \n[4] \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\"\n[5] \"filter: ikke i arbeid\"                                             \n\ntable(norlag$wr117zz)\n\n\n                                                               Nei \n                                                              1360 \n                                                                Ja \n                                                              4146 \n                                             filter: jobber deltid \n                                                              1964 \nfilter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet) \n                                                              1171 \n                                             filter: ikke i arbeid \n                                                              6238 \n\n\nLa oss si at vi vil kode om slik at vi får en variabel som bare er om vedkommende har mulighet til å jobbe deltid eller ikke. De som allerede jobber deltid har jo åpenbart mulighet til det, så de skal kodes om til “Ja”. De andre kategoriene er egentlig grunner til at det mangler data, så de skal settes til NA. En mulighet er da å omkode som følger:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == \"filter: jobber deltid\", \"Ja\"), \n         redarbtid = replace(redarbtid, redarbtid == \"filter: selvstendig næringsdrivende (NorLAG3 inkl frilanser/annet)\", NA), \n         redarbtid = replace(redarbtid, redarbtid == \"filter: ikke i arbeid\", NA), \n         redarbtid = replace(redarbtid, redarbtid == \"vil ikke svare\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"vet ikke\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"mangler data\", NA),\n         redarbtid = replace(redarbtid, redarbtid == \"Deltok ikke i runden\", NA)) %>% \n  droplevels()\n\nDette funker, men blir ganske mye tekst å skrive, og da kan man også lett gjøre skrivefeil. Husk at faktornivåene må angis helt nøyaktig slik de er skrevet! Merk at den siste funksjone, droplevels(), bare fjerner faktor-levels som ikke er i bruk.\nI output for faktor-levels angir klammeparentesen gir rekkefølgen på disse verdiene. Vi kan bruke denne informasjonen direkte i omkodingen for å unngå å skrive så veldig mye. Når man bruker levels() får man en liten vektor med verdier, og disse kan man altså henvise til med rekkefølgen. Her er et eksempel for bare å bytte ut de som jobber deltid til “Ja”:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == levels(wr117zz)[3], \"Ja\")) %>% \n  droplevels()\n\nTrikset her er altså å bruke levels() og vise til hvilket nummer i rekkefølgen. Da unngår vi også faren for skrivefeil.\nVi vil også kode om alle de andre verdiene, nummer 4-9 til NA. Det kan vi gjøre på samme måte, men vi behøver ikke skrive en ny linje for hver verdi. Den logiske operatoren == kan man bruke når man skal sjekke om to verdier er like. Hvis vi skal se om en verdi er lik en av flere mulige kan vi bruke %in% og så en liste med verdier. levels() gir en liste med verdier, så da kan vi angi den direkte og alle verdiene 4 til 9 ved å skrive 4:9. Samlet blir det da slik:\n\nnorlag_omkodet <- norlag %>%\n  mutate(redarbtid = replace(wr117zz, wr117zz == levels(wr117zz)[3], \"Ja\"), \n         redarbtid = replace(redarbtid, redarbtid %in% levels(wr117zz)[4:9], NA)) %>% \n  droplevels()\n\nmemisc::codebook(norlag_omkodet$redarbtid)\n\n================================================================================\n\n   norlag_omkodet$redarbtid\n\n--------------------------------------------------------------------------------\n\n   Storage mode: integer\n   Factor with 2 levels\n\n   Levels and labels     N Valid Total\n                                      \n    1 'Nei'           1360  18.2   4.1\n    2 'Ja'            6110  81.8  18.5\n   NA                25614        77.4"
  },
  {
    "objectID": "omkode_labelled.html",
    "href": "omkode_labelled.html",
    "title": "Appendix A — Omkoding av labelled-variable i innlesning fra Stata",
    "section": "",
    "text": "I tillegg skal vi bruke pakker for generell datahåndtering som er samlet i pakken {tidyverse}, deriblant en pakke {forcats} for håndtering av kategoriske variable.\n\nlibrary(tidyverse)   # Generelle funksjoner for datahåndtering\nlibrary(forcats)     # Funksjoner spesielt for factor-variable\n\nI dette kapittelet skal vi bruke følgende pakker:\n\nlibrary(haven)       # Importere data fra SAS, SPSS og Stata\nlibrary(tidyverse)   # Pakker for generell datahåndtering og grafikk\nlibrary(labelled)    # Håndtering av variable med labler, importert fra annen software\nlibrary(forcats)     # Lettere omkoding av faktorvariable\n\nDet er fult mulig å jobbe med data som inneholder labler og gjøre omkodinger basert på dette. Omkoding av variable avhenger av hva slags type variable det er, så man må gjøre det på en litt annen måte når det er snakk om labler.\nMitt anbefaling vil da være å gjøre all omkoding tidlig i scriptet\nNår man leser inn data som inkluderer labler kan man velge å omkode disse med en gang før man gjør om til factor-variable.\nI så fall kan det gjøres etter mønster som i følgende kode. Eller man kan vente til man har gjort om til factor-variable som forklares noe senere i dette dokumentet.\n\nnorlag <- read_stata(\"data/norlag_panel2022.dta\") %>% \n    mutate(across( where(is.labelled) ,  ~replace(., \n                                        . %in% c(997, 998, 999, 99999, 999999), \n                                        NA))) %>%\n  # For hele datasettet fjernes ikke-brukte labler \n  drop_unused_value_labels()  \n\nSå kan du gjøre andre analyser etter dette. Hvis du trenger å gå tilbake for å omkode flere labelled-variable, så legges dette til i mutate-setningen over. Det er lurt å gjøre all den typen omkoding ett sted, slik at du får et datasett som er ferdig ryddet og klart til andre analyser.\nLa oss si at vi det er mindre viktig om man har det romslig eller veldig romslig. Det er heller ikke så viktig å skille mellom de som ‘problemer’ og de som har det ‘svært vanskelig’. Da ønsker vi å slå sammen disse kategoriene.\nFor å omkode en variabel som har labler kan vi bruke recode(). Det gjør vi typisk innenfor en mutate-setning.\n\nFørste linje sier at det skal lages en ny variabel, som er en rekodet variant av he104\nAndre linje sier at alle med verdien 1 skal gjøres om til verdien 2\nTredje linje sier at alle med verdien 5 skal gjøres om til verdien 4\n\nLegg merke til at den opprinneligve verdien angis innenfor apostrof 1, mens den nye verdien ikke skal angis med apostrof.\n\nnorlag %>% \n  mutate(okonomi = recode(he104, \n                          `1` = 2 ,\n                          `5` = 4) ) %>% \n  select(okonomi) %>% \n  memisc::codebook()\n\n================================================================================\n\n   okonomi 'Hvordan vil du beskrive din økonomiske situasjon nå'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: double\n   Measurement: undefined\n\n   Values and labels                                       N Valid Total\n                                                                        \n    1   'Veldig romslig'                                   0   0.0   0.0\n    2   'Romslig'                                       9464  61.7  28.6\n    3   'Må være forsiktig, men klarer meg'             5152  33.6  15.6\n    4   'Problemer med å få pengene til å strekke til'   715   4.7   2.2\n    5   'Svært vanskelig økonomisk situasjon'              0   0.0   0.0\n   NA M                                                17753        53.7\n\n\nLegg merke til at de opprinnelge lablene fremdeles er der, men to av kategoriene har nå null observasjoner. Det innebærer jo også at lablene er litt misvisende, for det er jo egentlig kombinasjoner.\nÅ omkode lablene kan også gjøres. Funksjonen add_value_labels() angir hvilken variabel lablene skal angis for, og så settes ny label og hvilken verdi det tilsvarer. Lablene for verdier som ikke er nevnt blir beholdt slik de er.\n\nnorlag %>% \n  mutate(he104 = recode(he104, \n                          `1` = 2 ,\n                          `5` = 4,\n                        .combine_value_labels = TRUE) ) %>% \n  select(he104) %>% \n  add_value_labels(he104 = c(\"Romslig/veldig romslig\" = 2, \n                             \"Problemer/store problemer\" = 4)) %>% \n  memisc::codebook()\n\n================================================================================\n\n   he104 'Hvordan vil du beskrive din økonomiske situasjon nå'\n\n--------------------------------------------------------------------------------\n\n   Storage mode: double\n   Measurement: undefined\n\n   Values and labels                            N Valid Total\n                                                             \n    2   'Romslig/veldig romslig'             9464  61.7  28.6\n    3   'Må være forsiktig, men klarer meg'  5152  33.6  15.6\n    4   'Problemer/store problemer'           715   4.7   2.2\n   NA M                                     17753        53.7"
  }
]